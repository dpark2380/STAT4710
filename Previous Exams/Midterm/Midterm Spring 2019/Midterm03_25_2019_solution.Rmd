---
title: "Midterm"
author: "STAT 471/571/701 Modern Data Mining"
date: "03/25/2019"
output:
  pdf_document:
    toc: yes
    toc_depth: 4
  html_document:
    code_folding: show
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 7, fig.height = 4)
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, ggplot2, magrittr, gridExtra, reshape, rmarkdown, leaps, glmnet, knitr, pROC, reshape2, car)   #add your packages here
```




**Name your submission using the scheme:** 

`LastName_FirstName.pdf` etc. 

**For example:** `Zhao_Linda`  **.rmd**, **.pdf**, **.html** or **.docx**.

Instruction: This exam requires you to use R. It is completely open book/notes. Write your answers using .rmd format and knitr it into one of the html/pdf/docx format. Show your codes, plots or R-output when
needed. If you have trouble formatting the plots, don't worry about it. We are not looking for pretty solutions, rather to see if you are able to make sense out of data using R.

Data for Midterm: The data for midterm can be found at:

`/canvas/Files/Midterm/mortality_2012.csv`.

`/canvas/Files/Midterm/breast-cancer.csv`.

Midterm Question File can be found at:

`/canvas/Files/Midterm/Miderm03_25_2019.Rmd`.

**Help:** As always skip any part you have trouble with and you may come back to finish it if you have time. Ask one of us for help if you are stuck somewhere for technical issues.

**Electronic Submission:** In the `Assignments` section, go to the `Midterm` assignment and upload your completed files: your `.rmd` file and a compiled file (either a pdf/html/docx). You can upload multiple files. The folder will be closed at **08:10PM**.

If you have trouble to upload your files, email them to `lzhao@wharton.upenn.edu` and `arunku@wharton.upenn.edu`.

\newpage




## Part I: Mortality rate under age five

According to World Health Organization (WHO), 5.4 million children under age five died in 2017. The risk of a child dying before completing five years of age is still highest in Africa, 8 times compared to that in Europe. In addition, gaps of child mortality between high-income and low-income countries remain large. Reducing these inequalities across countries and saving more child lives by ending preventable child deaths are important priorities of WHO. 

In this exam, we will look into the mortality rate of children under age five of 115 countries around the world in 2012. The goal is to identify important factors associated with children mortality rate and to be able to quantify the relationship.

The data is obtained from DataBank of the World Bank. https://databank.worldbank.org/data/home.aspx. The following R-chunk reads the data `mortality_2012.csv`.


```{r read data}
# you need to put the dataset in the same folder
# where this .rmd file sits.
data <- read.csv("mortality_2012.csv")
```

|Variable|Description|
|----------------------|--------------------------------|
| mortality.rate | Mortality rate, under-5 (per 1,000 live births) |
|Country|Country name|
|adolescent.fertility.rate | Adolescent fertility rate (births per 1,000 women ages 15-19) |
| agri.forestry.fish.gdp.pct | Agriculture, forestry, and fishing, value added (% of GDP) |
| industry.gdp.pct | Industry (including construction), value added (% of GDP) | 
| CO2 | CO2 emissions (metric tons per capita) |
| fertility.rate | Fertility rate, total (births per woman) |
| GDP | GDP (current US$) |
| GDP.per.capita | GDP per capita (current US$) |
| gdp.grwoth.rate | GDP growth (annual %) |
| gni | GNI, PPP (current international $) |
| inflation | Inflation, GDP deflator (annual %) |
| LE | Life expectancy at birth, total (years) |
| population.growth | Population growth (annual %) |
| population | Population, total |
| unemployment | Unemployment, total (% of total labor force)) |
|Continent| Continent|
|Urban.pop|Percentage of urban population|
|Household.consump| Household consumption expenditure in million|
|Forest.area| Percentage of forest|
|Water| Access to improved water source in percentage|
|Food.prod.index| Food production index|
|Arable.land| Arable land per capita|
|Health.expend| Health expenditure percentage of GDP|
|Immunization| DPT Immunization percentage of children|
|Sanitation.faci| Access to improved sanitation facilities in percentage| 
|Immunization.measles| Measles Immunization percentage of children|
|Health.exp.pocket| Percentage of out of pocket health expenditure to total health| 
|Fixed.tel| Fixed telephone subscriptions per 100 people|
|Mobile.cel| Mobile cellular subscriptions per 100 people|
|Internet.users| Internet users per 100 people|



## Question 1: EDA of `data`

### a) Quick Summary

Report the following information about `data`:

**i)** How many variables and observations does `data` have?
```{r}
dim(data) # 115 observations and 30 variables
```

**ii)** Are there any missing values?
```{r}
sum(is.na(data)) # No.
```



### b) `mortality.rate`  in 2012

**i)** Which country has the highest `mortality.rate`? And which country has the lowest `mortality.rate`? What are the mean and median `mortality.rate`? 
```{r}
data$Country[which.min(data$mortality.rate)]
data$Country[which.max(data$mortality.rate)]
mean(data$mortality.rate)
median(data$mortality.rate)
hist(data$mortality.rate, breaks=20)
```
**ii)** Make a histogram of the `mortality.rate`. Use no more than three sentences to describe the distribution of the `mortality.rate`.  (Does it look normal? Are there more countries with low `mortality.rate` or more countries with high `mortality.rate`?)

**iii)**  Report the mean and median `mortality.rate` by `Continent`. Which `Continent` has the highest mean `mortality.rate` and what is the value? 
```{r}
data %>% group_by(Continent) %>%
  summarise(mean(mortality.rate), median(mortality.rate))
```

**iv)** Show the boxplots of `mortality.rate` versus `Continent`. Write a brief summary based on these boxplots. No more than three sentences please. 
```{r}
plot(data$mortality.rate ~ data$Continent)
data %>% group_by(Continent) %>% summarise(n())
```

## Question 2: Relation between mortality.rate and other variables

### a) Single most usueful factor

```{r, include=FALSE}
cor.mat <- data %>% select(-Country, -Continent) %>% cor   # Don't print the output from this chunk
cor.mat[1,]
```

Based on the above correlation matrix, which single continuous variable will have the highest $R^2$ if we fit `mortality.rate` vs one variable at a time and why? **We only take the answer based on the above R-chunk! No need to do all the simple linear regressions.**




### b) `mortality.rate` vs. GDP 

**i)** Fit a linear model of `mortality.rate` vs. GDP. Make a scatter plot of GDP vs. `mortality.rate`, together with the regression line overlayed.
Report the lm summary statistics. Is GDP a significant variable at .01 level?

**ii)** Fit a linear model of `mortality.rate` vs. log(GDP). Here we use natural log. Make another scatter plot of log(GDP) vs. `mortality.rate` together with the regression liner. Report the lm summary statistics. Is the GDP in log scale significant at .01 level?

**iii)** Which is a better model choice? And why? No more than three sentences. 

**iv)** Use your model in **ii)** regardless your answer in **iii)** and write your findings briefly (no more than 3 lines) summarizing the relationship between GDP and `mortality.rate`.


```{r}
# i)
summary(lm(mortality.rate~GDP, data))
ggplot(data,aes(x=GDP, y=mortality.rate)) + geom_point() +
  geom_smooth(method = 'lm', se=F) +
  labs( title =" GDP vs mortality.rate", x = "GDP", y = "Mortality Rate")
 
# ii)
summary(lm(mortality.rate~log(GDP), data))
ggplot(data,aes(x=log(GDP), y=mortality.rate)) + geom_point() +
  geom_smooth(method = 'lm', se=F)  +
  labs( title =" log(GDP) vs mortality rate", x = "log(GDP)", y = "mortality.rate")

# iii)
# The mortality.rate vs. log(GDP) is better.
# The scatter plot of mortality.rate vs. GDP shows the relationship between the two is clearly nonlinear

# iv)
# log(GDP) is significant at the .01 level. For a single unit change in log(GDP), on average, mortality.rate goes down by 9.032. 
```


### c) Relation between mortality.rate and other variables.
Now examine the relationship between mortality.rate vs Sanitation.faci, log(GDP) and Continent.

**i)** Fit a model of `mortality.rate` vs. Log(GDP), Sanitation.faci and Continent. Report the summary.
```{r}
# log GDP
data$log.gdp <- log(data$GDP)
# take away the original GDP
fit2 <- lm(mortality.rate~log.gdp+Sanitation.faci+Continent, data)
summary(fit2)
```

**ii)** Is log(GDP) a significant variable at .01 level after controlling for `Sanitation.faci` and `Continent`?
```{r}
# No. Its p-value is 0.081309 larger than 0.01.
```

**iii)** Are the means of mortality.rate among all Continents the same at .05 level after controlling for log(GDP) and `Sanitation.faci`?
```{r}
# This means test all Continent coefficients are zero. Remember the base is Africa so testing coefficients zero means testing all coefficients equal to that of Africa. Do Anova()
Anova(fit2)
# the p-value is 0.01044 less then 0.05 and hence we reject the null hypothesis that all coefficients are equal.
# iii) No. From the Anova table, we have strong evidence to reject the null hypotheses of all the continents being the same controlling for log(GDP).
```

**iv)** Based on this model fit, which Continent appears to have the highest mortality.rate after controlling for log(GDP) and `Sanitation.faci`? (No test needed.)

```{r}
# iv) Africa which is the base level of Continent.
```



## Question 3: Linear Model building

In this question, we build a model for `mortality.rate` based on the covariates available in data. Your professor insists on that GDP should have been taken a log scale. So from now on you may drop GDP from the working data but keep log(GDP) there to avoid any potential issues. Call this extracted data as `data1`. (Show your code for this.)

```{r}
data1 <- data %>% dplyr::select(-GDP, -Country) 
#str(data1)
```



### a) LASSO Regression: fit.lasso.0

**i)** Country names should not be a predictor. Explain why not? (one sentence only)



**ii)** LASSO Regression: fit.lasso.0

Use `cv.glmnet()` function on the data for the response `mortality.rate` on the covariates available. **Use the settings set.seed(471) and nfolds = 10.** (name this fit.lasso.0).


```{r}
set.seed(471)
X <- model.matrix(mortality.rate~.,data=data1)[,-1]
Y <- data1$mortality.rate
fit.lasso.0 <- cv.glmnet(X,Y, nfolds = 10)
plot(fit.lasso.0)
```

```{r}
# i)
# We cannot include Country because the data does not vary at the country level and as a result, a model with country would have no degrees of freedom to estimate anything.
```

**iii)**  What are the `lambda.min` and `lambda.1se` values? What are the covariates in `lambda = lambda.min` and `lambda = lambda.1se` models?
```{r}
# ii)
fit.lasso.0$lambda.min
# It represents value of lambda that gives minimum cvm. In this process, it thus gives us the lambda that results in the model with the lowest cvm, and can give us the variables used in said fit.
# ii)
coef.min <- coef(fit.lasso.0, s="lambda.min")  
coef.min <- coef.min[which(coef.min != 0),] 
coef.min


coef.1se <- coef(fit.lasso.0, s="lambda.1se")    
coef.1se <- coef.1se[which(coef.1se != 0),] 
coef.1se
```

### b) Lasso fit

**i)** Start with the `lambda = lambda.1se` model. Refit the linear model using `lm()` with the variables chosen. Perform backward elimination on this model until all features are significant at $\alpha = 0.1$ (**not 0.01**) level. Call this final model `fit.lasso`. Report the summary of `fit.lasso`.
```{r}
summary(lm(mortality.rate ~ adolescent.fertility.rate+agri.forestry.fish.gdp.pct+fertility.rate+Immunization+Sanitation.faci+Immunization.measles+Internet.users, data1  ))

summary(lm(mortality.rate ~ agri.forestry.fish.gdp.pct+fertility.rate+Immunization+Sanitation.faci+Immunization.measles+Internet.users, data1  ))

fit.lasso <- lm(mortality.rate ~ agri.forestry.fish.gdp.pct+fertility.rate+Immunization.measles+Internet.users, data1  )
summary(fit.lasso)
```

**ii)** Check to see if the linear model assumptions are reasonably met for `fit.lasso`. 
```{r}
plot(fit.lasso, 1)
plot(fit.lasso, 2)
data1[66, ]
data[66,]
```
**iii)** Report the summary and explain in (non-technical) words the what do coefficients/signs of covariates in `fit.lasso` imply. Inparticular, add a few sentences to suggest policy makers how to lower the mortality.rate for a country?


## Question 4: Prediction intervals

Lesotho is a country in Africa that is in the data set. 

**1)** Provide a 95% prediction interval of the `mortality.rate` for Lesotho. 

**2)** Is Lesotho's mortality.rate unusually high? Explain why or why not.

```{r}
predict(fit.lasso, data[66,],interval ="prediction", se.fit = TRUE)
data[66, ]
```

\newpage
Part II: Logistic regression/classification

## Part II: Breast Cancer Prediction

The diagnosis of breast tumors has traditionally been performed by a full biopsy, an invasive surgical procedure. Fine needle aspirations (FNAs) provide a way to examine a small amount of tissue from the tumor and the use of machine learning techniques allow classification of tumors as either benign or malignant. Features are computed from a digitized image of a fine needle	aspirate (FNA) of a breast mass. They describe	characteristics of the cell nuclei present in the image. Wisconsin Diagnostic Breast Cancer (WDBC) has collected data on several features of tumor cells for 569 patients.\footnote{The description of the data can be found at \url{https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names} and the data is obtained from Kaggle \url{https://www.kaggle.com/yuqing01/breast-cancer}.} 
\vspace{.1in}

You have seen some analysis of this dataset in Quiz 3. In this exam, you will do a more refined analysis. First load the dataset using the following code. 
```{r, data pareparation, eval = T}
# you need to put the dataset in the same folder where this .rmd file sits.
data.cancer <- read.csv("breast-cancer.csv")[,-c(1, 33)] 
names(data.cancer)
data.cancer$diagnosis <- ifelse(data.cancer$diagnosis == "M", 1, 0)
#data.cancer$diagnosis <- as.factor(data.cancer$diagnosis)
# str(data.cancer)
# split data into training and testing sets
set.seed(4712)
index.t <- sample(nrow(data.cancer), 100)
train_wdbc <- data.cancer[index.t, ]
test_wdbc  <- data.cancer[-index.t, ]
```


## Question 1: Data preparation

Throughout of the remaining exam, the response will be `diagnosis`. We have coded "M" to 1 and "B" to 0. 

Read the above R-Chunk carefully and answering the follwing questions

**i)** How many variables and observations does `data.cancer` have?
```{r}
dim(data.cancer)
# 569 observations and 31 variables.
```
**ii)** How many of the observations are there for `train_wdbc` and `test_wdbc`? 
```{r}
dim(train_wdbc) # 100 observations and 31 variables
dim(test_wdbc) # 469 observations and 31 variables
```

**iii)** What are the largest possible number in `index.t`?
```{r}
max(index.t) # 556.
```


## Question 2: Linear versus Logistic Regression

In lectures you have studied linear and logistic regression but never applied them on the same dataset. Lets apply logistic and linear regression for `diagnosis` on `area_worst` using `train_wdbc`.

### a) Logistic regression fit.glm

**i)** Report the probabilty equation of `P(diagnosis=1|area_worst)` using  `glm()`. Call this fit `fit.glm`.
```{r, eval = TRUE}
# logistic regression of diagnosis on area_worst.
fit.glm <- glm(diagnosis ~ area_worst, train_wdbc, family = binomial(logit))
fit.glm$coefficients
# Equation: P(diag = 1|area_worst) = exp(-8.110600271 + 0.009214652*area_worst)/(1 + exp(...))
```
**ii)** Use .5 as the thresholing on the probability equation. Report the misclassification errors using the testing data `test_wdbc`.
```{r}
fit.glm.pred <- predict(fit.glm, test_wdbc, type = "response") >= 0.5
mean(fit.glm.pred != test_wdbc$diagnosis)
# misclassification error is 0.07462687.
```

### b) Linear regreesioin fit.lm

As another method, one could use linear regression treating `diagonosis` as a continuese response variable and use the lm.fit to estimate the `P(diagnosis=1|area_worst)`. 

**i)** Fit linear  model using `lm()`, and call the fit to be fit.lm. Report the linear equation obtained. 
```{r}
# linear regression of diagnosis on area_worst.
fit.lm <- lm(diagnosis ~  area_worst, train_wdbc)  
fit.lm$coefficients
# Equation: diagnosis = -0.0628137600 + 0.0004569056
```

**ii)** Use .5 as the thresholing on the probability this fit.lm equation. Report the misclassification errors using the testing data `test_wdbc`.
```{r}
fit.lm.pred <- predict(fit.lm, test_wdbc) >= 0.5
mean(fit.lm.pred != test_wdbc$diagnosis)
# misclassification error is 0.1599147.
```
### c) Findings

Which method yielded a better classification rule with smaller testing misclassification error? Write a couple of sentences to comment on the fundamental differences between fit.lm and fit.glm.
```{r}
# fit.glm yielded a better result than fit.lm which is probably expected in that fit.glm respects the fact that diagnosis is a categorial variable while fit.lm does not. 
```


\vspace{0.1in}


**Declaration**
By submitting this document you certify that you have complied with the University of Pennsylvania's Code of Academic Integrity, to the best of your knowledge. You further certify that you have taken this exam
under its sanctioned conditions, i.e. solely within the set exam room and within the time allotted.