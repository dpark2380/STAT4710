---
title: "COVID-19 Case Study - Midterm"
author:
- Jessica Brown
date: '28 March 2022'
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
    number_sections: no
  pdf_document:
    toc_depth: '4'
    number_sections: no
urlcolor: blue
---

```{r Setup, include=FALSE, results='hide', warning=FALSE}
knitr::opts_chunk$set(echo = T, fig.width=8, fig.height=4)
options(scipen = 999, digits = 3)  # controls base R output

# Package setup
if(!require("pacman")) install.packages("pacman")

pacman::p_load(car, tidyverse, dplyr, ggplot2, data.table, lubridate, glmnet, kableExtra, stargazer)
```

# Instruction

**All the teaching team members will be available from 7:00 - 9:10 PM.  The submission will be closed sharp at 9:10PM.** 


**Instruction:** This midterm requires you to use R. It is completely open book/notes/internet. Write your answers using .rmd format and knitr it into one of the html/pdf/docx format. Show your codes, plots or R-output when needed. You can use `echo = TRUE` to show your codes which is the default setup for this file. If you have trouble formatting the plots, don't worry about it. We are not looking for pretty solutions, rather to see if you are able to make sense out of the data using R. Make sure the compiled pdf/html/docx (only one of them) shows your answers completely and that they are not cut-off. Throughout the exam, you do not need to use any LaTeX or mathematical equations. **Whenever we ask for test at some significant level, assume all the model assumptions are satisfied.**

**All the answers should be clearly supported by relevant R code or based on the R output**. 

There are 4 questions with various parts:

- **Question 1: 3 parts**
- **Question 2: 3 parts**
- **Question 3: 1 parts**
- **Question 4: 9 parts**

**DO NOT spend too much time on a single question. Come back to where you stuck after you have tried all the questions.**


**Data needed for the Midterm:** `/canvas/Files/Exams/Midterm/Midterm Spring 2022/data/covid_county_midterm_spring_2022.csv` 



**Electronic Submission:** Two files needed: your `.rmd` file and a compiled file (either a pdf/html/docx). **Label them with your full name.** In the `Assignments` section, go to the `Midterm` assignment and upload your completed files. If you have trouble submitting the files to Canvas, email them to lzhao@wharton.upenn.edu and rosesamk@sas.upenn.edu. 

**The submission folder will be closed sharp at 9:10PM**. 



**On-site Help:** 

We will answer any clarification questions. We may also help out with some minor code issues. We will, however, not provide any answers as to what functions to use for example. 

**Raise your hand** if you want to talk to one of us.
   
In case of emergency, here is Linda's cell: 6106590187 (text or call her)


# Background

The outbreak of the novel Corona virus disease 2019 (COVID-19) [was declared a public health emergency of international concern by the World Health Organization (WHO) on January 30, 2020](https://www.who.int/dg/speeches/detail/who-director-general-s-statement-on-ihr-emergency-committee-on-novel-coronavirus-(2019-ncov)). Upwards of [112 million cases have been confirmed worldwide, with nearly 2.5 million associated deaths](https://covid19.who.int/). Within the US alone, there have been [over 500,000 deaths and upwards of 28 million cases reported](https://covid.cdc.gov/covid-data-tracker/#trends_dailytrendscases). Governments around the world have implemented and suggested a number of policies to lessen the spread of the pandemic, including mask-wearing requirements, travel restrictions, business and school closures, and even stay-at-home orders. The global pandemic has impacted the lives of individuals in countless ways, and though many countries have begun vaccinating individuals, the long-term impact of the virus remains unclear.

The impact of COVID-19 on a given segment of the population appears to vary drastically based on the socioeconomic characteristics of the segment. In particular, differing rates of infection and fatalities have been reported among different [racial groups](https://www.cdc.gov/coronavirus/2019-ncov/covid-data/investigations-discovery/hospitalization-death-by-race-ethnicity.html), [age groups](https://www.cdc.gov/coronavirus/2019-ncov/covid-data/investigations-discovery/hospitalization-death-by-age.html), and [socioeconomic groups](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7221360/). One of the most important metrics for determining the impact of the pandemic is the death rate, which is the proportion of people within the total population that die due to the the disease. 


**There are two main goals for this case study.** 

1. Number of deaths vary drastically across State. We want to find out how State relate to the death rate.

2. There have been studies on COVID racial disparities. Is there evidence in our data to show that the proportion of race relates to the death at county level?

To make our case study here simple and manageable in a timely fashion, we have assembled a subset of data called: `covid_county_midterm_spring_2022.csv`. It includes county level total number of deaths by a chosen date, together with selected demographic information. `State` names is also included in the data. The name of each variable should be self-explanatory. 




# 1. Data preparation


In this case study, we have created `covid_county_midterm_spring_2022.csv` based on the following two cleaned datasets. We will focus on the east coast, i.e., Connecticut, District of Columbia, Maine, Massachusetts, New Hampshire, New Jersey, New York, Pennsylvania, Maryland, Rhode Island and Vermont.

* **covid_county.csv**: County-level socioeconomic information that combines the above-mentioned 4 datasets: Income (Poverty level and household income), Jobs (Employment type, rate, and change), People (Population size, density, education level, race, age, household size, and migration rates), County Classifications
* **covid_rates.csv**: Daily cumulative numbers on infection and fatality for each county

**Among all data, the unique identifier of county is `FIPS`.**


## Question 1: (3 parts)

What is a good way to measure COVID death rate? There are quite a number of counties with a very low or zero number of deaths. We have proposed an effective way of handling such an imbalanced situation. In the following chunk, we created a new measurement of death-rate then applied the log function to get the variable labeled as `log_death_rate`. We then created the data `covid_county_midterm_spring_2022.csv` by combining the `log_death_rate` with a subset of county level demographic information.  The process of creating this data is shown in the following R-chunk, labeled as `data prep`. Read through the `data prep` chunk carefully and please answer the following questions. 

**Note:**

- Do not run this chunk!!!!! Notice the `eval=F`. 
- Regardless your answers to the following questions, it will not affect the remaining case study at all.


**i.** The total number of death for each county is gathered by which day? 

**Answer**: The total number of deaths is gathered for the day 09/01/2020 or September 1, 2020.


**ii.** Use plain language to describe how the death-rate (before taking log) is defined for each county? 

**Answer**: The death rate (before taking log) is defined as the cumulative deaths for that county on the selected day (9/1/2020) + 1 divided by the total population estimate for 2019 (TotalPopEst2019) + 2. (also known as (cum_deaths+1)/(TotalPopEst2019+2))

```{r, data prep, eval = F}
# This is how we created the covid_county_midterm_spring_2022.csv
# DONOT RUN this chunk

# county-level socialeconomic information
county_data <- fread("data/covid_county.csv") 
# county-level COVID case and death
covid_rate <- fread("data/covid_rates.csv")

# northeast regions
northeast <- c("CT", "DC", "ME", "MA", "NH", 
               "NJ", "NY", "PA", "MD", "RI", "VT")

covid_county_temp <- covid_rate %>% 
  filter(date == "2020-09-01") %>% 
  mutate(log_death_rate = log( (cum_deaths+1)/(TotalPopEst2019+2) )) %>%
  select(FIPS, cum_deaths, log_death_rate)

# join with county-level demographic data
covid_county_temp <- 
  left_join(covid_county_temp,
            county_data, 
            by = "FIPS") %>% 
  filter(State %in% northeast) %>% 
  
  drop_na()

# take a subset of the demographic info
covid_county_sub <- covid_county_temp %>%
  select(log_death_rate, State, Deep_Pov_All, PovertyAllAgesPct, PerCapitaInc, UnempRate2019, PctEmpFIRE, PctEmpConstruction, PctEmpTrans, PctEmpMining, PctEmpTrade, PctEmpInformation, PctEmpAgriculture, PctEmpManufacturing, PctEmpServices, PopDensity2010, OwnHomePct, Age65AndOlderPct2010, TotalPop25Plus, Under18Pct2010, Ed2HSDiplomaOnlyPct, Ed3SomeCollegePct, Ed4AssocDegreePct, Ed5CollegePlusPct, ForeignBornPct, Net_International_Migration_Rate_2010_2019, NetMigrationRate1019, NaturalChangeRate1019, TotalPopEst2019, WhiteNonHispanicPct2010, Type_2015_Update, RuralUrbanContinuumCode2013, UrbanInfluenceCode2013, Perpov_1980_0711, HiCreativeClass2000, HiAmenity, Retirement_Destination_2015_Update)

# output
fwrite(covid_county_sub, "data/covid_county_midterm_spring_2022.csv")
```


We next read the pre-processed data `covid_county_midterm_spring_2022.csv` into R and label it as `covid_county`. 

**Note `covid_county_midterm_spring_2022.csv` is stored in a directory called `data`.** 

**`covid_county` will be used throughout the midterm.** 

```{r read data}
covid_county <- read.csv("data/covid_county_midterm_spring_2022.csv") # let's not use fread to avoid unexpected problems.
```

**iii.** For the `covid_county`, how many variables are included here? How many counties are there in this data? Are there any missing values in this data? 

```{r}
print(ncol(covid_county))
print(nrow(covid_county))
print(sum(is.na(covid_county)))
```


**Answer**: There are 37 variables and 242 counties in the dataset. There are no missing values in the data. 


# 2. EDA

During the course of pandemic, policies are usually implemented at state level and thus vary among states, which may further lead to the variability of death rate among states. We first study the death rates at state level via the following EDA. 

## Question 2: (3 parts)

**i.** Report number of counties by State.

```{r}
covid_county %>% group_by(State) %>% summarise(n())
```


**Answer**: There are 8 counties from CT, 1 from DC, 14 from MA, 24 from MD, 16 from ME, 10 from NH, 21 from NJ, 62 from NY, 67 from PA, 5 from RI, and 14 from VT. 


**ii.** Create the median `log_death_rate` by State and output the table. Based on the table which state has the highest median of `log_death_rate`? And what is the corresponding highest median of `log_death_rate`? (Hint: you can find the highest median directly from the table. No need to use R.)

```{r}
covid_county %>% group_by(State) %>% summarise(med_death_rate = median(log_death_rate))
```


**Answer**: NJ has the highest median of log_death_rate with a median value of -6.42. 


**iii.** To compare `log_death_rate` across `State` and the county level variability within `State`, make a box-plot of `log_death_rate` by `State`. Use no more than two sentences to describe the comparison of `log_death_rate` by `State` and the variability within each `State`. Why does DC not have a box in the plot? (No need to order the boxes by median.)

```{r}
covid_county %>% 
  ggplot(aes(x = State, y = log_death_rate, group = State)) + 
  geom_boxplot() + 
  ggtitle("County Level Variability of Log Death Rate Per State") + 
  ylab("Log Death Rate") 
```


**Answer**: From the boxplot we can see that NY has the largest variability with its counties' log death rates and NJ has the highest median value (confirming what we found before). We can also see some outlier counties in MA, MD, ME, and RI. DC does not have a box in this plot, since, as found earlier with the county counts, there is only one county in the data for DC and so with one datapoint the entire distribution is one point or one line as a boxplot.



# 3. Analyses

There are a number of studies indicating that COVID affected minority groups more.
In the following analyses, we focus on the effect of `WhiteNonHispanicPct2010` over `log_death_rate`. 

## Question 3: (1 part)

## 3.1 fit1

Run a regression of `log_death_rate` vs. `WhiteNonHispanicPct2010` controlling `State`  (without interactions)  as `fit1`. 

```{r}
fit1 <- lm(log_death_rate ~ WhiteNonHispanicPct2010 + State, data = covid_county)
```


**i.** Report the summary table of `fit1`. Is `WhiteNonHispanicPct2010` a significant variable at the .01 level controlling for `State`? Use no more than 2 sentences to interpret the coefficient of `WhiteNonHispanicPct2010` over the `log_death_rate` in `fit1`.

```{r}
summary(fit1)
```


**Answer**: WhiteNonHispanicPct2010 is shown to be a significant variable at the 0.01 level controlling for state given that it has a very low p-value (much less than 0.01). We can also see that ignoring state, on average an increase in 1% of the White Non-Hispanic Percentage in 2010 decreases the log death rate by 0.03811. 


## Question 4: (9 parts)

## 3.2 fit.final

In this section, using all possible variables available in `covid_county`, we will build a final parsimonious model  to identify a set of important variables that are related to `log_death_rate` using first LASSO  then backward elimination (using 0.01 significance).

As you have seen `State` explains a large portion of variability in `log_death_rate`, **we will keep `State` in all the following questions.**


Notes:

*In case you cannot get LASSO to work at all,* **skip Q4.i-iii, jump to Q4.iv** *and use the following set of variables to build your final model `fit.final`: State, PctEmpServices, PopDensity2010, Age65AndOlderPct2010, WhiteNonHispanicPct2010, HiCreativeClass2000. Note: this is unnecessarily the LASSO output or the set of variables selected from back elimination.*



**i.** Use LASSO to pick up a few variables in addition to `State`. To be specific let us control the following settings to get the same results. 

* Use `set.seed(1)` to control the cross-validation
* Use 12-fold cross validations
* Force `State` in all the LASSO models 
* Pick up the variables using  `lambda.1se` 

Report the variables selected by the LASSO.

```{r}
set.seed(1)
X <- model.matrix(log_death_rate~., covid_county)[,-1]
y <- covid_county$log_death_rate
state_indicator <- c(rep(0, 10), rep(1, ncol(X)-10))

lasso_model <- cv.glmnet(X, y, nfolds = 12, alpha = 1, penalty.factor = state_indicator)
plot(lasso_model)
```

```{r}
coef.1se <- coef(lasso_model, s="lambda.1se")
coef.1se <- coef.1se[which(coef.1se !=0),][-1]
var.1se <- rownames(as.matrix(coef.1se))
state_indicator <- !(grepl("State", var.1se))
lasso_sub <- covid_county %>%
  select(log_death_rate, State, var.1se[state_indicator])
names(lasso_sub)
```


**Answer**: Including State which is forced in to the LASSO model, the LASSO selected: PctEmpFIRE, ForeignBornPct, TotalPopEst2019, WhiteNonHispanicPct2010, and UrbanInfluenceCode2013. 


**ii.** Is `lambda.1se` a reasonable choice to have a small testing error? Use the LASSO plot to support your statement. 

**Answer**: We can see from the LASSO plot and the second dashed line representing lambda.1se that the testing error (MSE) is a reasonable choice, although lambda.min returns a smaller MSE value so it may be preferable for a smaller testing error. 


**iii.** 
Start with the set of variables obtained from your LASSO output.
Run backward elimination until all variables are significant at 0.01 level as the final set of variables. Always keep `State` in the model. Show the backward selection procedure and report the final set of variables. (Hint: `regsubsets()` is not applicable here).

```{r}
model2 <- lm(log_death_rate~., lasso_sub)
Anova(model2)
```

```{r}
back_select <- lasso_sub %>% select(-ForeignBornPct)
model3 <- lm(log_death_rate ~., back_select)
Anova(model3)
```

```{r}
back_select2 <- back_select %>% select(-TotalPopEst2019)
model4 <- lm(log_death_rate ~., back_select2)
anova(model3, model4)
```

```{r}
Anova(model4)
```


**Answer**: First, using all the variables selected by LASSO, using Anova we can see that at a 0.01 significance level, TotalPopEst2019 and ForeignBornPct are not significant in the model. I decided to first remove ForeignBornPct since it was far from being significant and then found that TotalPopEst2019 was still not significant in the model at the 0.01 level so I removed that as well. The final set of variables, with each significant in the model at the 0.01 level includes: State, PctEmpFIRE, WhiteNonHispanicPct2010, and UrbanInfluenceCode2013. 


**iv.** Run a final model `fit.final` of `log_death_rate` vs the set of variables from backward elimination (Q4.iii). Also include `WhiteNonHispanicPct2010` regardless since we know the death rate among the elderly is higher. Report the summary of `fit.final`. 


**Answer**: Since we indeed found that WhiteNonHispanicPct2010 was significant in the model, we can just use the variables found from back selection for fit.final. 

```{r}
#WhiteNonHispanicPct2010 is already incldued so nothing to add
fit.final <- lm(log_death_rate ~., back_select2)
summary(fit.final)
```


**v.** Is `WhiteNonHispanicPct2010` significant at .01 level controlling for all other variables in `fit.final`?  

```{r}
Anova(fit.final)
```


**Answer**: WhiteNonHispanicPct2010 is significant at the 0.01 level as shown in the summary of the model and using Anova. 


**vi.** Is `State` significant at .01 level controlling for all other variables in `fit.final`? Which State has the largest `log_death_rate` controlling for all other variables in `fit.final`?
(Hint: you can answer the question directly from the summary table of `fit.final`. No need to use R.)

**Answer**: State is significant at the 0.01 level in fit.final as shown in the Anova results. The State with the largest log_death_rate controlling for all other variables is MA or Massachusetts with a coefficient of 0.4193 (compared to the baseline of CT). 


**vii.** Are the linear model assumptions reasonably met in `fit.final`? Provide residual and normal plots for `fit.final` and summarize your model diagnoses. (No more than 3 sentences).

```{r}
plot(fit.final, 1)
```

```{r}
plot(fit.final, 2)
```


**Answer**: First, from the residual plot we can't see any pattern with the residuals which implies linearity. We can also see that the residuals are somewhat evenly distributed within a band which implies homoscedasticity. Lastly, from the normal quantile plot we can see that the residuals are mostly situated on the line with a little tailing off on the left end implying normality or a normal distribution of the residuals, so altogether the linear model assumptions are reasonably met. 


**viii.** Based on `fit.final`, write down the **prediction equation** for a county with the following characteristics:

- State: NJ
- PctEmpServices: 48.5
- PctEmpFIRE: 11.3
- PctEmpTrans: 7.97 
- PctEmpMining: 0.0114
- PopDensity2010: 13731
- TotalPopEst2019: 672391
- ForeignBornPct: 42.77
- Age65AndOlderPct2010: 10.4
- WhiteNonHispanicPct2010: 30.8
- UrbanInfluenceCode2013: 1
- HiCreativeClass2000: 1
- Deep_Pov_All: 7.15
- NetMigrationRate1019: -3.255

**No calculation needed.**

**Answer**: log_death_rate = -6.2509 + 0.3743 + (0.1466 * 11.3) + (-0.0249 * 30.8) + (-0.1111 * 1)


**ix.** Assume all linear model assumptions are met. Write a brief summary of your findings based on `fit.final`. (No more than 4 sentences).

**Answer**: Addressing the first of our two intial questions, from fit.final we found that the State in which a county is located has a significant affect on its log death rate. For example, we found that the state of Massachusetts (MA) increases the log death rate the most on average (~0.42) while Maine (ME) decreases the log rate the most on average (~-1.12) compared to a baseline of Connecticut. To address the second question, we did find that the proportion of race does have a significant relationship to the death at county level, given that the variable WhiteNonHispanicPct2010 is significant in the fit.final model. To be more exact, we found that on average a 1% increase in the White Non-Hispanic percentage decreased the log death rate of a county by 0.0249 (holding all other variables constant). 


# **End** of the case study!!!!




# Appendix {-}

## Data Summary {-}

The data comes from several different sources: 

1. [County-level infection and fatality data](https://github.com/nytimes/covid-19-data) - This dataset gives daily cumulative numbers on infection and fatality for each county. 
    * [NYC data](https://github.com/nychealth/coronavirus-data)
2. [County-level socioeconomic data](https://www.ers.usda.gov/data-products/atlas-of-rural-and-small-town-america/download-the-data/) - The following are the four relevant datasets from this site.   
    i. Income - Poverty level and household income. 
    ii. Jobs - Employment type, rate, and change.
    iii. People - Population size, density, education level, race, age, household size, and migration rates.
    iv. County Classifications - Type of county (rural or urban on a rural-urban continuum scale).
