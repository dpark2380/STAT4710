---
title: "Quiz 2"
author: "Modern Data Mining/Linda"
date: "March 1, 2022"
output:
  pdf_document:
    keep_tex: yes
  html_document:
    df_print: paged
fontfamily: mathpazo
fontsize: 11pt
geometry: margin=1in
header-includes:
- \linespread{1.05}
- \usepackage{framed}
- \usepackage{fancyvrb}
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      fig.height=5, fig.width=8, cache = TRUE)
options(scipen = 1, digits = 2)
library("pacman")
pacman::p_load(tidyverse, dplyr, ggplot2, magrittr, gridExtra, reshape, rmarkdown, leaps, glmnet, knitr, skimr, olsrr, car)
options(xtable.comment = FALSE)
```

\makebox[\textwidth]{\textbf{Name}: \enspace\hrulefill}
\vspace{0.4in}
\makebox[\textwidth]{\textbf{Section (471, 571, 701)}:\enspace\hrulefill}


This is an open book, 10-minute quiz. Choose the correct answer(s). There might be more than one right answer in some questions. No calculations are needed. 

Insurance companies try to charge a higher premium than the amount paid to the insured. For this reason, insurance companies invest a lot of time, effort, and money in creating models that are able to accurately predict health care costs. In order to fulfill this mission, we would build an adequate model and optimize its performance.

We have a dataset that includes 1338 observations on 7 variables:

- `age`: The age of the policy holder.
- `sex`: The sex of the policy holder. Values: (`male`, `female`)
- `bmi`: The Body Mass Index of the policy holder. BMI gives an understanding of body weights that are relatively high or low relative to height.
- `children`: The number of dependents the policy holder has.
- `smoker`: Whether the policy holder smokes. Values: (`yes`, `no`)
- `region`: Part of the US the policy holder lives in. Values: (`northeast`, `southeast`, `southwest`, `northwest`)
- `charges`: Medical costs billed to the policy holder.


Our goal of the study is to understand how each variable affects the response `charges` and build a good linear model to predict `charges`. We will only include the non-smokers and convert the variables `sex` and `region` to categorical variables; the rest of variables is regarded as continuous type. We use `lcharges = log(charges)` as the response.

```{r}
url <- 'https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv'
df_all <- read_csv(url, col_types = cols(.default="d", sex="f", smoker="f", region="f"))
df <- df_all %>% 
  filter(smoker == "no") %>% 
  select(-smoker) %>%
  mutate(lcharges = log(charges))
head(df)
```



# Simple Regression

We first run a linear regression of `lcharges` on `region` using `df`. Recall that there are 4 regions: `northeast`, `southeast`, `southwest`, `northwest`.

```{r}
fit1 <- lm(lcharges ~ region, data = df) 
summary(fit1)
```


1. True or False? Based on the summary table of `fit1`, we CANNOT reject the null hypothesis that the average `lcharges` for policy holder from southwest region is the same as that from northeast origin under significance level $\alpha = .05$.

(A) TRUE

(B) FALSE

**Answer: (A). `southwest` is the base level in this analysis. The coef for `northeast` is the mean difference of `lcharges` between `northeast` and `southwest`.**

2. According to the `fit1`, what is the average `lcharges` for policy holders from southeast?

(A) `r round(fit1$coeff[1], 2)`

(B) `r round(fit1$coeff[2], 2)`

(C) `r round(fit1$coeff[1], 2)` `r round(fit1$coeff[2], 2)`

**The answer is (C).**

We then fit a linear regression model of `lcharges` on `age`.

```{r}
fit2 <- lm(lcharges ~ age, data = df) 
summary(fit2)
```




3. Based on summary of `fit2`, choose correct answer(s)

(A) Age is statistically significant at level $\alpha = .05$.

(B) On average, a 25-year-old male is likely to be charged `r fit2$coeff[2]` more than a 24-year-old female.

**The answer is both (A) and (B) since `age` is not included in the model.**

\pagebreak

# Building a better model

We construct a linear model `lcharges` including more covariates.
```{r}
fit3 <- lm(lcharges ~ age + sex + children + region, data=df)
summary(fit3)
```

4. True or False? Based on the summary of `fit3`, because `regionsoutheast` and `regionnorthwest` both have p-values larger than 0.001, we conclude at level $\alpha=.001$ that there is no effect of policy holder's region over insurance premium in this model.

(A) TRUE

(B) FALSE

**The answer is (B). 


5. True or False? Based on the summary of `fit3`, even though region `southeast` is not significant at level $\alpha=.05$, it CAN be statistically significant when we account for more variables.

(A) TRUE

(B) FALSE

**The answer is (A).**

6. Choose the correct answer. Based on `fit3`, we would like to estimate the mean of `lcharges` for a customer with the following measurement: `age = 50`, `sex = Female`, `bmi = 30`, `children = 5` and `region = southwest`. 

(A) We can not do it since `bmi` is not included in `fit3`.

(B) 
\[`r fit3$coeff[1]` + 50 \times `r fit3$coeff[2]` + 5 \times`r fit3$coeff[4]` \]

(C) 
\[`r fit3$coeff[1]` + 50 \times `r fit3$coeff[2]` + 5 \times`r fit3$coeff[4]` + `r fit3$coeff[5]` \]

(D) 
\[`r fit3$coeff[1]` + 50 \times `r fit3$coeff[2]` `r fit3$coeff[3]` + 5 \times`r fit3$coeff[4]` \]

**The answer is (C).**

We extend the previous model to contain additional interaction terms.

```{r}
fit4 <- lm(lcharges ~ age + sex + bmi + children  + region + 
            age*sex + bmi*sex, data=df)
Anova(fit4)
```

7. True or False? Based on the `Anova` table of `fit4`, `region` is significant at 0.05 level.

(A) TRUE

(B) FALSE

**The answer is (A).** 

8. We want to estimate the prediction error of model `fit4`. Choose the correct metric(s).

(A) Mallow $C_p$ 

(B) BIC 

(C) Both (A) and (B). 

(D) Neither (A) nor (B).

**The answer is (A).** Once again $C_p$ estimates testing errors. 

9. We implement the best subsets regression. (we use a different package to calculate the Cp but it does the same thing as regsubsets).

```{r}
selection_result <- olsrr::ols_step_best_subset(fit4)

as_tibble(selection_result) %>% 
  transmute(model=mindex, predictors, Mallow_Cp=cp)
```

Based on Mallow's $C_p$, which model has the smallest prediction error?

(A) model 2

(B) model 4

(C) model 6

(D) model 8

**The answer is (B).**














